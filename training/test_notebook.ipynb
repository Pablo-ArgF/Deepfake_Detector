{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, MaxPooling2D, Conv2D,MaxPooling3D, Conv3D, Flatten,Lambda, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from faceRecon import FaceExtractorMultithread, FaceExtractor\n",
    "\n",
    "route = '/home/pabloarga/Data'\n",
    "\n",
    "print('Loading dataframes...')\n",
    "fragments = []\n",
    "for i in range(5):\n",
    "    # Assuming each dataframe is stored as a separate table in the HDF5 file\n",
    "    if i%10==0:\n",
    "        print(f'{i} dataframes loaded')\n",
    "    chunk = pd.read_hdf(f'{route}/dataframe{i}_FaceForensics.h5', key=f'df{i}')\n",
    "    fragments.append(chunk)\n",
    "#fragments = [pd.read_hdf(f'dataframes/CelebDB/dataframe{i}_600videos.h5', key=f'df{i}') for i in range(2)]#6\n",
    "df = pd.concat(fragments)\n",
    "\n",
    "print(df.describe())\n",
    "print(df.dtypes)\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "X = df.drop(['label'], axis = 1)\n",
    "y = df['label']\n",
    "\n",
    "print('Dividing dataset into train and test...')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42, stratify = y)\n",
    "X_train = np.stack(X_train['face'], axis=0)\n",
    "X_test = np.stack(X_test['face'], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating model...')\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(200, 200, 3)))\n",
    "model.add(Lambda(lambda x: x/255.0)) #normalizamos los valores de los pixeles\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))  # Dropout for regularization\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout for regularization\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MetricsModule import TrainingMetrics\n",
    "#prueba de que imprime las stats\n",
    "metrics = TrainingMetrics(model,\"/home/pabloarga/Results\")\n",
    "metrics.train(X_train, y_train, X_test, y_test, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test de bach training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.layers import Dense, MaxPooling2D, Conv2D, Flatten,Lambda,  Input,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from MetricsModule import TrainingMetrics\n",
    "\n",
    "route =  'P:\\TFG\\Datasets\\dataframes_small' #'/home/pabloarga/Data' \n",
    "resultsPath = 'P:\\TFG\\Datasets\\dataframes_small\\\\results' #'/home/pabloarga/Results'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(200, 200, 3)))\n",
    "model.add(Lambda(lambda x: x/255.0)) #normalizamos los valores de los pixeles -> mejora la eficiencia\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))  # Dropout for regularization\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))  # Dropout for regularization\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Input(shape=(200, 200, 3)))\n",
    "model2.add(Lambda(lambda x: x/255.0)) #normalizamos los valores de los pixeles -> mejora la eficiencia\n",
    "model2.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dropout(0.2))  # Dropout for regularization\n",
    "model2.add(Dense(512, activation='relu'))\n",
    "model2.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Input(shape=(200, 200, 3)))\n",
    "model3.add(Lambda(lambda x: x/255.0)) #normalizamos los valores de los pixeles -> mejora la eficiencia\n",
    "model3.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model3.add(MaxPooling2D((2, 2)))\n",
    "model3.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model3.add(MaxPooling2D((2, 2)))\n",
    "model3.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model3.add(MaxPooling2D((2, 2)))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dropout(0.2))  # Dropout for regularization\n",
    "model3.add(Dense(512, activation='relu'))\n",
    "model3.add(Dropout(0.3))  # Dropout for regularization\n",
    "model3.add(Dense(512, activation='relu'))\n",
    "model3.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MetricsModule import TrainingMetrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n",
    "\n",
    "# Congelar las capas del modelo base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Crear un nuevo modelo encima del modelo base\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "metrics = TrainingMetrics(model, resultsPath)\n",
    "metrics.batches_train(route,nBatches = 1 , epochs = 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importamos el modelo y probamos con un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from FaceReconModule import FaceExtractorMultithread\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "modelPath = os.path.join(resultsPath,'model.keras')\n",
    "\n",
    "#cargamos un video y lo procesamos frame por frame\n",
    "videoPath = 'P:\\TFG\\Datasets\\FaceForensics\\manipulated_sequences-fake\\DeepFakeDetection\\c23\\\\videos\\\\01_15__outside_talking_pan_laughing__02HILKYO.mp4'\n",
    "#creamos un dataframe con el path al video y con la label 0 de fake\n",
    "df = pd.DataFrame({'video': [videoPath], 'label': [0]})\n",
    "faceExtractor = FaceExtractorMultithread(400) #cada 2 frames\n",
    "imagesDataset = faceExtractor.transform(df)\n",
    "\n",
    "print(imagesDataset['face'])\n",
    "\n",
    "#Cargamos el modelo\n",
    "model = load_model(modelPath,safe_mode=False)\n",
    "#probamos el modelo manualmente\n",
    "y_pred = model.predict(np.stack(imagesDataset['face'], axis=0))\n",
    "#matriz de confusión\n",
    "y_real = imagesDataset['label']\n",
    "print(confusion_matrix(y_real, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests on datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, MaxPooling2D, Conv2D,MaxPooling3D, Conv3D, Flatten,Lambda, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from FaceReconModule import FaceExtractorMultithread, FaceExtractor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "TODO comentar\n",
    "\"\"\"\n",
    "def augment(row):\n",
    "    image = np.array(row['face']).reshape((200, 200, 3))  # Replace height and width with the dimensions of your images\n",
    "\n",
    "    # Perform augmentations only on fake images\n",
    "    if row['label'] == 1:\n",
    "        # Flip the image\n",
    "        flipped_image = np.fliplr(image)\n",
    "        # Rotate the image\n",
    "        rotated_image = ndimage.rotate(image, 15)  # Adjust the angle as needed\n",
    "\n",
    "        # Add the augmented images as new examples\n",
    "        new_row_flipped = row.copy()\n",
    "        new_row_flipped['face'] = flipped_image.flatten().tolist()\n",
    "        new_row_flipped['label'] = 1\n",
    "        new_row_rotated = row.copy()\n",
    "        new_row_rotated['face'] = rotated_image.flatten().tolist()\n",
    "        new_row_rotated['label'] = 1\n",
    "\n",
    "        return pd.DataFrame([row, new_row_flipped, new_row_rotated])\n",
    "\n",
    "    return pd.DataFrame([row])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "folderPath = 'E:\\TFG\\Datasets\\dataframes\\\\valid\\\\dataframes_combined'\n",
    "\n",
    "nBatches = 10\n",
    "\n",
    "numDataframes = len([name for name in os.listdir(folderPath) if os.path.isfile(os.path.join(folderPath, name))])\n",
    "#Calculamos el tamaño de cada fragmento\n",
    "fragmentSize = int(numDataframes/nBatches)\n",
    "\n",
    "for i in range(nBatches):\n",
    "    fragments = [pd.read_hdf(f'{folderPath}/dataframe{j}_FaceForensics.h5', key=f'df{j}') for j in range(fragmentSize*i,fragmentSize*(i+1))]\n",
    "    df = pd.concat(fragments)\n",
    "    #contamos el número de fakes y reales en el dataframe\n",
    "    print(df['label'].value_counts())\n",
    "    #print(\"After augmentation\")\n",
    "    #df = pd.concat(df.apply(augment, axis=1).tolist(), ignore_index=True)\n",
    "    #print(df['label'].value_counts())\n",
    "    print('-------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "\n",
    "#cargamos el modelo del escritorio\n",
    "modelPath = '/home/pabloarga/Results/2024-03-04 14.39.53/model2024-03-04 14.39.53.keras'\n",
    "videoTest = '/home/pabloarga/testVideos/testVideo.mp4'\n",
    "\n",
    "#Cargamos el modelo\n",
    "model = load_model(modelPath,safe_mode=False,compile=False)\n",
    "#obtenemos el número de frames del video\n",
    "cap = cv2.VideoCapture(videoTest)\n",
    "nFramesVideo = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "#Procesamos el video frame por frame\n",
    "faceExtractor = FaceExtractorMultithread(nFramesVideo) #cada 2 frames\n",
    "frames = faceExtractor.process_video(videoTest,1)[0]\n",
    "\n",
    "#probamos el modelo manualmente\n",
    "y_pred = model.predict(np.stack(frames, axis=0))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 18:56:51.706437: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TrainingMetrics' object has no attribute 'storeTrainingScript'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 77\u001b[0m\n\u001b[1;32m     74\u001b[0m resultsPathServer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/pabloarga/MiniData\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[1;32m     76\u001b[0m metrics \u001b[38;5;241m=\u001b[39m TrainingMetrics(model, resultsPathServer, modelDescription \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatches_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrouteServer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnBatches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Divide the whole dataset into <nbatches> fragments and train <epochs> epochs with each\u001b[39;00m\n",
      "File \u001b[0;32m~/Deepfake_Detector/training/MetricsModule.py:102\u001b[0m, in \u001b[0;36mTrainingMetrics.batches_train\u001b[0;34m(self, folderPath, nBatches, epochs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatches_train\u001b[39m(\u001b[38;5;28mself\u001b[39m,folderPath,nBatches,epochs):\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m#Guardamos una copia del archivo de entrenamiento en la carpeta del modelo\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstoreTrainingScript\u001b[49m()\n\u001b[1;32m    104\u001b[0m     fileNames \u001b[38;5;241m=\u001b[39m [name \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(folderPath) \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folderPath, name))]\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m#Hacemos un shuffle a los archivos para mezclar los dataframes\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TrainingMetrics' object has no attribute 'storeTrainingScript'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.layers import Dense, MaxPooling2D, Conv2D, Flatten, Lambda, Input, Dropout, PReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from MetricsModule import TrainingMetrics\n",
    "\n",
    "# Define the constant value for PReLU alpha\n",
    "value_PReLU = 0.25\n",
    "\n",
    "# Input Layer\n",
    "inputs = layers.Input(shape=(200, 200, 3))\n",
    "\n",
    "# Function to add Convolutional layer with PReLU activation\n",
    "def conv_prelu(filters, kernel_size, name):\n",
    "    conv_layer = layers.Conv2D(filters, kernel_size, padding='same', name=name)\n",
    "    prelu_layer = PReLU(alpha_initializer=Constant(value=value_PReLU))\n",
    "    return Sequential([conv_layer, prelu_layer])\n",
    "\n",
    "# Conv1_1 and Conv1_2 Layers\n",
    "x = conv_prelu(64, (3, 3), 'conv1_1')(inputs)\n",
    "x = conv_prelu(64, (3, 3), 'conv1_2')(x)\n",
    "x = layers.Dropout(0.25)(x)  # Adding dropout after Conv1_2\n",
    "\n",
    "# Pool1 Layer\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "# Conv2_1 and Conv2_2 Layers\n",
    "x = conv_prelu(128, (3, 3), 'conv2_1')(x)\n",
    "x = conv_prelu(128, (3, 3), 'conv2_2')(x)\n",
    "x = layers.Dropout(0.25)(x)  # Adding dropout after Conv2_2\n",
    "\n",
    "# Pool2 Layer\n",
    "pool2_output = layers.MaxPooling2D((2, 2), strides=(2, 2), name='pool2')(x)\n",
    "\n",
    "# Now you can use pool2_output as input for other layers\n",
    "conv3_1 = conv_prelu(128, (3, 3), 'conv3_1')(pool2_output)\n",
    "conv3_2 = conv_prelu(128, (3, 3), 'conv3_2')(conv3_1)\n",
    "pool3 = layers.MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(conv3_2)\n",
    "conv4_1 = conv_prelu(128, (3, 3), 'conv4_1')(pool3)\n",
    "conv4_2 = conv_prelu(128, (3, 3), 'conv4_2')(conv4_1)\n",
    "\n",
    "conv5_2 = conv_prelu(128, (3, 3), 'conv5_2')(pool2_output)\n",
    "conv5_3 = conv_prelu(128, (3, 3), 'conv5_3')(conv5_2)\n",
    "\n",
    "conv5_1 = conv_prelu(128, (3, 3), 'conv5_1')(pool2_output)\n",
    "concat_1 = layers.Concatenate(name=\"concat_1\")([conv3_2, conv5_1, conv5_3])\n",
    "pool5 = layers.MaxPooling2D((2, 2), strides=(2, 2), name='pool5')(concat_1)\n",
    "\n",
    "conv6_2 = conv_prelu(128, (3, 3), 'conv6_2')(pool5)\n",
    "conv6_3 = conv_prelu(128, (3, 3), 'conv6_3')(conv6_2)\n",
    "\n",
    "conv6_1 = conv_prelu(128, (3, 3), 'conv6_1')(pool5)\n",
    "concat_2 = layers.Concatenate(name=\"concat_2\")([conv4_2, conv6_1, conv6_3])\n",
    "\n",
    "pool4 = layers.MaxPooling2D((2, 2), strides=(2, 2), name='pool4')(concat_2)\n",
    "\n",
    "flatten = Flatten()(pool4)\n",
    "\n",
    "#fc = layers.Dense(1024, name='fc')(flatten)\n",
    "#fc = layers.Dropout(0.5)(fc)  # Adding dropout before the fully connected layer\n",
    "\n",
    "#fc_class = layers.Dense(4096, name='fc_class')(fc)\n",
    "\n",
    "# Softmax Output Layer\n",
    "outputs = layers.Dense(1, activation='sigmoid', name='out')(flatten)\n",
    "\n",
    "# Compile the model (add optimizer, loss function, etc.)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "routeServer = '/home/pabloarga/MiniData'\n",
    "resultsPathServer = '/home/pabloarga/MiniData' \n",
    "\n",
    "metrics = TrainingMetrics(model, resultsPathServer, modelDescription = 'test')\n",
    "metrics.batches_train(routeServer, nBatches=1, epochs=1)  # Divide the whole dataset into <nbatches> fragments and train <epochs> epochs with each\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import base64\n",
    "import sys\n",
    "#My modules\n",
    "sys.path.append(\"..\")\n",
    "from training.DataProcessing.FaceReconModule import FaceExtractorMultithread\n",
    "\n",
    "faceExtractor = FaceExtractorMultithread() \n",
    "\n",
    "# Process the video\n",
    "video_path = '/home/pabloarga/testVideos/fakeVideo_wwe.mp4'\n",
    "videoFrames, processedFrames = faceExtractor.process_video_to_predict(video_path)\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(np.stack(processedFrames, axis=0))\n",
    "predictions = [float(value) for value in predictions]\n",
    "mean = np.mean(predictions)\n",
    "\n",
    "{\n",
    "    'predictions': {\n",
    "        'data': predictions\n",
    "    },\n",
    "    'mean': mean,\n",
    "    'nFrames': len(predictions),\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepFakeDetector",
   "language": "python",
   "name": "deepfakedetector"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
