{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, MaxPooling2D, Conv2D,MaxPooling3D, Conv3D, Flatten,Lambda, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from faceRecon import FaceExtractorMultithread, FaceExtractor\n",
    "\n",
    "route = '/home/pabloarga/Data'\n",
    "\n",
    "print('Loading dataframes...')\n",
    "fragments = []\n",
    "for i in range(5):\n",
    "    # Assuming each dataframe is stored as a separate table in the HDF5 file\n",
    "    if i%10==0:\n",
    "        print(f'{i} dataframes loaded')\n",
    "    chunk = pd.read_hdf(f'{route}/dataframe{i}_FaceForensics.h5', key=f'df{i}')\n",
    "    fragments.append(chunk)\n",
    "#fragments = [pd.read_hdf(f'dataframes/CelebDB/dataframe{i}_600videos.h5', key=f'df{i}') for i in range(2)]#6\n",
    "df = pd.concat(fragments)\n",
    "\n",
    "print(df.describe())\n",
    "print(df.dtypes)\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "X = df.drop(['label'], axis = 1)\n",
    "y = df['label']\n",
    "\n",
    "print('Dividing dataset into train and test...')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42, stratify = y)\n",
    "X_train = np.stack(X_train['face'], axis=0)\n",
    "X_test = np.stack(X_test['face'], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating model...')\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(200, 200, 3)))\n",
    "model.add(Lambda(lambda x: x/255.0)) #normalizamos los valores de los pixeles\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))  # Dropout for regularization\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout for regularization\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MetricsModule import TrainingMetrics\n",
    "#prueba de que imprime las stats\n",
    "metrics = TrainingMetrics(model,\"/home/pabloarga/Results\")\n",
    "metrics.train(X_train, y_train, X_test, y_test, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test de bach training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.layers import Dense, MaxPooling2D, Conv2D, Flatten,Lambda,  Input,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from MetricsModule import TrainingMetrics\n",
    "\n",
    "route =  'P:\\TFG\\Datasets\\dataframes_small' #'/home/pabloarga/Data' \n",
    "resultsPath = 'P:\\TFG\\Datasets\\dataframes_small\\\\results' #'/home/pabloarga/Results'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(200, 200, 3)))\n",
    "model.add(Lambda(lambda x: x/255.0)) #normalizamos los valores de los pixeles -> mejora la eficiencia\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))  # Dropout for regularization\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))  # Dropout for regularization\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Input(shape=(200, 200, 3)))\n",
    "model2.add(Lambda(lambda x: x/255.0)) #normalizamos los valores de los pixeles -> mejora la eficiencia\n",
    "model2.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dropout(0.2))  # Dropout for regularization\n",
    "model2.add(Dense(512, activation='relu'))\n",
    "model2.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Input(shape=(200, 200, 3)))\n",
    "model3.add(Lambda(lambda x: x/255.0)) #normalizamos los valores de los pixeles -> mejora la eficiencia\n",
    "model3.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model3.add(MaxPooling2D((2, 2)))\n",
    "model3.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model3.add(MaxPooling2D((2, 2)))\n",
    "model3.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model3.add(MaxPooling2D((2, 2)))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dropout(0.2))  # Dropout for regularization\n",
    "model3.add(Dense(512, activation='relu'))\n",
    "model3.add(Dropout(0.3))  # Dropout for regularization\n",
    "model3.add(Dense(512, activation='relu'))\n",
    "model3.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model with batch: 1/1\n",
      "Epoch 1/2\n",
      "130/130 [==============================] - 273s 2s/step - loss: 0.2284 - accuracy: 0.9505 - val_loss: 0.0494 - val_accuracy: 0.9913\n",
      "Epoch 2/2\n",
      "130/130 [==============================] - 278s 2s/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.0622 - val_accuracy: 0.9923\n",
      "33/33 [==============================] - 51s 2s/step\n"
     ]
    }
   ],
   "source": [
    "from MetricsModule import TrainingMetrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n",
    "\n",
    "# Congelar las capas del modelo base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Crear un nuevo modelo encima del modelo base\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "metrics = TrainingMetrics(model, resultsPath)\n",
    "metrics.batches_train(route,nBatches = 1 , epochs = 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importamos el modelo y probamos con un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from FaceReconModule import FaceExtractorMultithread\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "modelPath = os.path.join(resultsPath,'model.keras')\n",
    "\n",
    "#cargamos un video y lo procesamos frame por frame\n",
    "videoPath = 'P:\\TFG\\Datasets\\FaceForensics\\manipulated_sequences-fake\\DeepFakeDetection\\c23\\\\videos\\\\01_15__outside_talking_pan_laughing__02HILKYO.mp4'\n",
    "#creamos un dataframe con el path al video y con la label 0 de fake\n",
    "df = pd.DataFrame({'video': [videoPath], 'label': [0]})\n",
    "faceExtractor = FaceExtractorMultithread(400) #cada 2 frames\n",
    "imagesDataset = faceExtractor.transform(df)\n",
    "\n",
    "print(imagesDataset['face'])\n",
    "\n",
    "#Cargamos el modelo\n",
    "model = load_model(modelPath,safe_mode=False)\n",
    "#probamos el modelo manualmente\n",
    "y_pred = model.predict(np.stack(imagesDataset['face'], axis=0))\n",
    "#matriz de confusión\n",
    "y_real = imagesDataset['label']\n",
    "print(confusion_matrix(y_real, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests on datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    14104\n",
      "1     3982\n",
      "Name: count, dtype: int64\n",
      "After augmentation\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts())\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter augmentation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist(), ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts())\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:10034\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m  10022\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10024\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10025\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10026\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10032\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10033\u001b[0m )\n\u001b[1;32m> 10034\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:837\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:963\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 963\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:979\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 979\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    981\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    982\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    983\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[3], line 42\u001b[0m, in \u001b[0;36maugment\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     38\u001b[0m     new_row_rotated[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame([row, new_row_flipped, new_row_rotated])\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:693\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    690\u001b[0m         NDFrame\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data)\n\u001b[0;32m    691\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 693\u001b[0m manager \u001b[38;5;241m=\u001b[39m \u001b[43mget_option\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmode.data_manager\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;66;03m# GH47215\u001b[39;00m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, \u001b[38;5;28mset\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_config\\config.py:272\u001b[0m, in \u001b[0;36mCallableDynamicDoc.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m--> 272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__func__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_config\\config.py:146\u001b[0m, in \u001b[0;36m_get_option\u001b[1;34m(pat, silent)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_option\u001b[39m(pat: \u001b[38;5;28mstr\u001b[39m, silent: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 146\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43m_get_single_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;66;03m# walk the nested dict\u001b[39;00m\n\u001b[0;32m    149\u001b[0m     root, k \u001b[38;5;241m=\u001b[39m _get_root(key)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_config\\config.py:140\u001b[0m, in \u001b[0;36m_get_single_key\u001b[1;34m(pat, silent)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silent:\n\u001b[0;32m    138\u001b[0m     _warn_if_deprecated(key)\n\u001b[1;32m--> 140\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[43m_translate_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m key\n",
      "File \u001b[1;32mc:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_config\\config.py:679\u001b[0m, in \u001b[0;36m_translate_key\u001b[1;34m(key)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_translate_key\u001b[39m(key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    675\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;124;03m    if key id deprecated and a replacement key defined, will return the\u001b[39;00m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;124;03m    replacement key, otherwise returns `key` as - is\u001b[39;00m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 679\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[43m_get_deprecated_option\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m d:\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m d\u001b[38;5;241m.\u001b[39mrkey \u001b[38;5;129;01mor\u001b[39;00m key\n",
      "File \u001b[1;32mc:\\Users\\pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_config\\config.py:647\u001b[0m, in \u001b[0;36m_get_deprecated_option\u001b[1;34m(key)\u001b[0m\n\u001b[0;32m    643\u001b[0m     key \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m _deprecated_options\n\u001b[1;32m--> 647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_deprecated_option\u001b[39m(key: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    648\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;124;03m    Retrieves the metadata for a deprecated option, if `key` is deprecated.\u001b[39;00m\n\u001b[0;32m    650\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;124;03m    DeprecatedOption (namedtuple) if key is deprecated, None otherwise\u001b[39;00m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, MaxPooling2D, Conv2D,MaxPooling3D, Conv3D, Flatten,Lambda, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from FaceReconModule import FaceExtractorMultithread, FaceExtractor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "TODO comentar\n",
    "\"\"\"\n",
    "def augment(row):\n",
    "    image = np.array(row['face']).reshape((200, 200, 3))  # Replace height and width with the dimensions of your images\n",
    "\n",
    "    # Perform augmentations only on fake images\n",
    "    if row['label'] == 1:\n",
    "        # Flip the image\n",
    "        flipped_image = np.fliplr(image)\n",
    "        # Rotate the image\n",
    "        rotated_image = ndimage.rotate(image, 15)  # Adjust the angle as needed\n",
    "\n",
    "        # Add the augmented images as new examples\n",
    "        new_row_flipped = row.copy()\n",
    "        new_row_flipped['face'] = flipped_image.flatten().tolist()\n",
    "        new_row_flipped['label'] = 1\n",
    "        new_row_rotated = row.copy()\n",
    "        new_row_rotated['face'] = rotated_image.flatten().tolist()\n",
    "        new_row_rotated['label'] = 1\n",
    "\n",
    "        return pd.DataFrame([row, new_row_flipped, new_row_rotated])\n",
    "\n",
    "    return pd.DataFrame([row])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "folderPath = 'P:\\TFG\\Datasets\\dataframes_int'\n",
    "\n",
    "nBatches = 10\n",
    "\n",
    "numDataframes = len([name for name in os.listdir(folderPath) if os.path.isfile(os.path.join(folderPath, name))])\n",
    "#Calculamos el tamaño de cada fragmento\n",
    "fragmentSize = int(numDataframes/nBatches)\n",
    "\n",
    "for i in range(nBatches):\n",
    "    fragments = [pd.read_hdf(f'{folderPath}/dataframe{j}_FaceForensics.h5', key=f'df{j}') for j in range(fragmentSize*i,fragmentSize*(i+1))]\n",
    "    df = pd.concat(fragments)\n",
    "    #contamos el número de fakes y reales en el dataframe\n",
    "    print(df['label'].value_counts())\n",
    "    print(\"After augmentation\")\n",
    "    df = pd.concat(df.apply(augment, axis=1).tolist(), ignore_index=True)\n",
    "    print(df['label'].value_counts())\n",
    "    print('-------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepFakeDetector",
   "language": "python",
   "name": "deepfakedetector"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
